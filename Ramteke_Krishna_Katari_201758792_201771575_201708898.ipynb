from pyspark.sql import functions as F
import matplotlib.pyplot as plt

# =========================
# 0) Choose the dataset to check duplicates on
#    (Use df_OPPM for full data quality checks)
# =========================
df_base = df_OPPM

# =========================
# 1) Clean leader name columns
# =========================
df_base = (
    df_base
    .withColumn("pm_clean",  F.when(F.col("pm").isNull()  | (F.trim(F.col("pm")) == ""),  F.lit("Unknown"))
                            .otherwise(F.trim(F.col("pm").cast("string"))))
    .withColumn("spm_clean", F.when(F.col("spm").isNull() | (F.trim(F.col("spm")) == ""), F.lit("Unknown"))
                            .otherwise(F.trim(F.col("spm").cast("string"))))
    .withColumn("lpm_clean", F.when(F.col("lpm_name").isNull() | (F.trim(F.col("lpm_name")) == ""), F.lit("Unknown"))
                            .otherwise(F.trim(F.col("lpm_name").cast("string"))))
)

# =========================
# 2) A) Project ID repeated in the dataset (duplicate Project IDs)
# =========================
df_project_dups = (
    df_base.groupBy("Project ID")
           .agg(F.count("*").alias("row_count"))
           .filter(F.col("row_count") > 1)
           .orderBy(F.desc("row_count"))
)

print("Duplicate Project IDs (Project ID appears in multiple rows):")
display(df_project_dups.limit(50))

# Optional: show the duplicated rows (sample) with leaders
df_project_dups_sample = (
    df_base.join(df_project_dups.select("Project ID"), on="Project ID", how="inner")
           .select("Project ID", "Project Title", "pm_clean", "spm_clean", "lpm_clean")
           .orderBy("Project ID")
)
display(df_project_dups_sample.limit(100))

# =========================
# 2) B) Same Project ID led by multiple different leaders (handover/inconsistency)
# =========================
df_project_multi_leader = (
    df_base.groupBy("Project ID")
           .agg(
               F.countDistinct("pm_clean").alias("distinct_pm"),
               F.countDistinct("spm_clean").alias("distinct_spm"),
               F.countDistinct("lpm_clean").alias("distinct_lpm"),
               F.countDistinct(F.struct("pm_clean","spm_clean","lpm_clean")).alias("distinct_leader_combo"),
               F.count("*").alias("row_count")
           )
           .filter(
               (F.col("distinct_pm") > 1) |
               (F.col("distinct_spm") > 1) |
               (F.col("distinct_lpm") > 1) |
               (F.col("distinct_leader_combo") > 1)
           )
           .orderBy(F.desc("distinct_leader_combo"), F.desc("row_count"))
)

print("Projects where leadership fields vary across rows (same Project ID, different pm/spm/lpm):")
display(df_project_multi_leader.limit(50))

# Show detail for these projects
df_project_multi_leader_detail = (
    df_base.join(df_project_multi_leader.select("Project ID"), "Project ID", "inner")
           .select("Project ID", "Project Title", "pm_clean", "spm_clean", "lpm_clean")
           .orderBy("Project ID", "pm_clean", "spm_clean", "lpm_clean")
)
display(df_project_multi_leader_detail.limit(200))

# =========================
# 3) C) Repeats per leader (PM / SPM / LPM):
#    "projects they lead gets repeated" = same (leader, Project ID) appears in multiple rows
# =========================
def repeats_by_role(role_col_clean: str, role_label: str):
    # same leader + same project appearing multiple rows => repeated
    df_role_project_counts = (
        df_base.groupBy(role_col_clean, "Project ID")
               .agg(F.count("*").alias("rows_for_that_leader_project"))
    )

    df_repeated = df_role_project_counts.filter(F.col("rows_for_that_leader_project") > 1)

    # Summarise by leader:
    # - repeated_projects: how many Project IDs are repeated for that leader
    # - extra_rows: how many extra duplicate rows (count-1 summed)
    # - repeated_rows_total: total rows involved in repeats
    df_summary = (
        df_repeated.groupBy(role_col_clean)
                   .agg(
                       F.countDistinct("Project ID").alias("repeated_projects"),
                       F.sum(F.col("rows_for_that_leader_project") - 1).alias("extra_rows_due_to_repeats"),
                       F.sum("rows_for_that_leader_project").alias("rows_in_repeated_groups")
                   )
                   .orderBy(F.desc("repeated_projects"), F.desc("extra_rows_due_to_repeats"))
                   .withColumnRenamed(role_col_clean, role_label)
    )

    return df_summary, df_repeated

pm_summary, pm_repeated_pairs   = repeats_by_role("pm_clean",  "pm")
spm_summary, spm_repeated_pairs = repeats_by_role("spm_clean", "spm")
lpm_summary, lpm_repeated_pairs = repeats_by_role("lpm_clean", "lpm_name")

print("PMs with repeated projects (same PM + Project ID appears multiple rows):")
display(pm_summary.limit(30))

print("SPMs with repeated projects:")
display(spm_summary.limit(30))

print("LPMs with repeated projects:")
display(lpm_summary.limit(30))

# =========================
# 4) Bar charts: Top 15 leaders with most repeated projects
# =========================
def plot_top_bar(df_summary, leader_col_name, title, top_n=15):
    pdf = df_summary.limit(top_n).toPandas()
    if pdf.empty:
        print(f"No repeats found for {title}.")
        return
    plt.figure(figsize=(10, 4))
    plt.barh(pdf[leader_col_name][::-1], pdf["repeated_projects"][::-1])
    plt.xlabel("Number of repeated Project IDs")
    plt.ylabel(leader_col_name)
    plt.title(title)
    plt.tight_layout()
    plt.show()

plot_top_bar(pm_summary,  "pm",       "Top PMs by Repeated Project IDs",  top_n=15)
plot_top_bar(spm_summary, "spm",      "Top SPMs by Repeated Project IDs", top_n=15)
plot_top_bar(lpm_summary, "lpm_name", "Top LPMs by Repeated Project IDs", top_n=15)
