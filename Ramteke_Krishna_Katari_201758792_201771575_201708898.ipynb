from pyspark.sql import functions as F, types as T
from dateutil import parser

# ----------------------------
# 0) Start from your filtered analysis DF (as you requested)
# ----------------------------
df = df_analysed.filter((F.col("benchmark_eligible") == 1) & (F.col("is_sequence_full") == 1))

# ----------------------------
# 1) Gate column mapping
#    (Approval Value fields treated as "planned/expected dates")
# ----------------------------
gate_map = [
    ("A2", "Gate A2 Decision Date", "Gate A2 Approval Value"),
    ("B",  "Gate B Decision Date",  "Gate B Approval Value Sanction"),
    ("C",  "Gate C Decision Date",  "Gate C Approval Value FSA ACL"),
    ("D",  "Gate D Decision Date",  "Gate D Approval Value"),
    ("E",  "Gate E Decision Date",  "Gate E Approval Value"),
]

# ----------------------------
# 2) Date parsing helpers (Spark first, then python-dateutil fallback)
# ----------------------------
def parse_date_spark(colname: str):
    c = F.trim(F.col(colname).cast("string"))
    c = F.when((c == "") | c.isNull(), F.lit(None)).otherwise(c)

    # Try multiple common formats (extend as needed)
    return F.coalesce(
        F.to_date(c, "yyyy-MM-dd"),
        F.to_date(c, "yyyy/MM/dd"),
        F.to_date(c, "dd/MM/yyyy"),
        F.to_date(c, "MM/dd/yyyy"),
        F.to_date(c, "dd-MM-yyyy"),
        F.to_date(c, "MM-dd-yyyy"),
        F.to_date(c, "dd-MMM-yyyy"),   # 05-Jan-2024
        F.to_date(c, "dd-MMM-yy"),     # 05-Jan-24 / 05-Jan-90
        F.to_date(c, "MMM dd, yyyy"),
        F.to_date(F.to_timestamp(c))
    )

@F.udf(returnType=T.DateType())
def parse_date_dateutil(s: str):
    if s is None:
        return None
    s = s.strip()
    if s == "":
        return None
    try:
        dt = parser.parse(s, fuzzy=True, dayfirst=True)  # UK-style day-first
        return dt.date()
    except Exception:
        return None

# Fix Spark "yy" century issue (01-Jan-90 -> 2090). Shift back 100 years if it ends with -90/-91/...
def fix_century_209x(parsed_date_col, raw_col):
    # Only adjust if parsed year is 2090-2099 AND raw ends with "-9x" or "/9x"
    return F.when(
        (parsed_date_col.isNotNull()) &
        (F.year(parsed_date_col).between(2090, 2099)) &
        (F.trim(raw_col).rlike(r".*[-/]\s*9[0-9]\s*$")),
        F.add_months(parsed_date_col, -1200)  # -100 years
    ).otherwise(parsed_date_col)

analysis_date = F.current_date()   # or use your extract_date if you have one

# ----------------------------
# 3) Standardise ALL Approval Value columns -> *_Approval_Date
# ----------------------------
for gate, decision_col, approval_col in gate_map:
    raw = F.trim(F.col(approval_col).cast("string"))
    spark_parsed = parse_date_spark(approval_col)

    parsed = F.when(spark_parsed.isNotNull(), spark_parsed) \
              .when((raw.isNotNull()) & (raw != ""), parse_date_dateutil(raw)) \
              .otherwise(F.lit(None).cast("date"))

    parsed = fix_century_209x(parsed, raw)

    df = df.withColumn(f"Gate {gate} Approval Date", parsed)

# ----------------------------
# 4) Timeliness: Approval Date âˆ’ Decision Date + status flags
# ----------------------------
for gate, decision_col, approval_col in gate_map:
    approval_date_col = F.col(f"Gate {gate} Approval Date")
    decision_date_col  = F.col(decision_col)

    # As requested: planned/expected minus actual
    df = df.withColumn(
        f"{gate}_approval_minus_decision_days",
        F.when(approval_date_col.isNotNull() & decision_date_col.isNotNull(),
               F.datediff(approval_date_col, decision_date_col)
        ).otherwise(F.lit(None).cast("int"))
    )

    # Also compute the more intuitive "delay" (actual - planned) for interpretation
    df = df.withColumn(
        f"{gate}_delay_days_actual_minus_planned",
        F.when(approval_date_col.isNotNull() & decision_date_col.isNotNull(),
               F.datediff(decision_date_col, approval_date_col)
        ).otherwise(F.lit(None).cast("int"))
    )

    # Timeliness flag:
    # - If actual exists -> Early/On time/Late
    # - If actual missing -> Upcoming vs Overdue (based on current date vs planned)
    df = df.withColumn(
        f"{gate}_timeliness_flag",
        F.when(approval_date_col.isNull(), F.lit("NO_PLAN"))
         .when(decision_date_col.isNotNull() & (decision_date_col < approval_date_col), F.lit("EARLY"))
         .when(decision_date_col.isNotNull() & (decision_date_col == approval_date_col), F.lit("ON_TIME"))
         .when(decision_date_col.isNotNull() & (decision_date_col > approval_date_col), F.lit("LATE"))
         .when(decision_date_col.isNull() & (analysis_date > approval_date_col), F.lit("OVERDUE"))
         .otherwise(F.lit("UPCOMING"))
    )

# ----------------------------
# 5) Quick sanity checks (optional but recommended)
# ----------------------------

# a) See parsing success rates for planned dates
parsing_summary = df.select(
    *[
        F.sum(F.when(F.col(f"Gate {g} Approval Date").isNotNull(), 1).otherwise(0)).alias(f"{g}_planned_parsed_cnt")
        for g, _, _ in gate_map
    ]
)
display(parsing_summary)

# b) View a sample with planned vs actual + flags
cols_to_show = ["Project ID", "project_status_gate_based"]
for g, dcol, _ in gate_map:
    cols_to_show += [
        f"Gate {g} Approval Date", dcol,
        f"{g}_timeliness_flag",
        f"{g}_delay_days_actual_minus_planned"
    ]

display(df.select(*cols_to_show).limit(50))

