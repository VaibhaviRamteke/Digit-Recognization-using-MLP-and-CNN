from pyspark.sql import functions as F
from pyspark.sql import types as T

# -----------------------------
# Inputs
# -----------------------------
df = df_analysed
as_of_date = F.current_date()   # or use your extract_date column if you have it

# Your planned/expected date columns (raw "Approval Value" fields)
approval_cols = [
    "Gate A2 Approval Value",
    "Gate B Approval Value Sanction",
    "Gate C Approval Value FSA ACL",
    "Gate D Approval Value",
    "Gate E Approval Value"
]

# Matching actual decision date columns
decision_cols = [
    "Gate A2 Decision Date",
    "Gate B Decision Date",
    "Gate C Decision Date",
    "Gate D Decision Date",
    "Gate E Decision Date"
]

# -----------------------------
# 1) Date parsing helpers
# -----------------------------
# Spark-native multi-format parser + Excel-serial-date support + 1990 fix for "-90"
def parse_mixed_date(colname: str):
    raw = F.trim(F.col(colname).cast("string"))
    raw = F.when(raw.isNull() | (raw == ""), F.lit(None)).otherwise(raw)

    # Excel serial date support (if values like 45000 etc appear)
    excel_int = F.when(raw.rlike(r"^\d+$"), raw.cast("int"))
    excel_date = F.when(excel_int.between(1, 60000), F.date_add(F.lit("1899-12-30"), excel_int)).otherwise(F.lit(None))

    spark_parsed = F.coalesce(
        F.to_date(raw, "yyyy-MM-dd"),
        F.to_date(raw, "yyyy/MM/dd"),
        F.to_date(raw, "dd/MM/yyyy"),
        F.to_date(raw, "MM/dd/yyyy"),
        F.to_date(raw, "dd-MM-yyyy"),
        F.to_date(raw, "MM-dd-yyyy"),
        F.to_date(raw, "dd-MMM-yyyy"),
        F.to_date(raw, "dd-MMM-yy"),
        F.to_date(raw, "MMM dd, yyyy"),
        F.to_date(F.to_timestamp(raw)),
        excel_date
    )

    # Fix: if Spark interprets 01-Jan-90 as 2090, map to 1990 (ONLY when raw ends with 90)
    ends_90 = F.regexp_like(raw, r".*[-/ ]90$")
    spark_fixed = F.when(ends_90 & (F.year(spark_parsed) == 2090), F.add_months(spark_parsed, -1200)).otherwise(spark_parsed)

    return raw, spark_fixed

# dateutil fallback for messy strings Spark can't parse
from dateutil import parser

@F.udf(returnType=T.DateType())
def parse_date_dateutil(s: str):
    if s is None:
        return None
    s = s.strip()
    if s == "":
        return None
    try:
        dt = parser.parse(s, fuzzy=True, dayfirst=True)
        return dt.date()
    except Exception:
        return None

# -----------------------------
# 2) Standardise planned/expected (Approval Value) columns into DATE columns
#    We'll create new columns: "<Approval Col>__date"
# -----------------------------
for c in approval_cols:
    raw, spark_fixed = parse_mixed_date(c)
    df = df.withColumn(
        f"{c}__date",
        F.when(spark_fixed.isNotNull(), spark_fixed)
         .when((raw.isNotNull()) & (raw != ""), parse_date_dateutil(raw))
         .otherwise(F.lit(None).cast("date"))
    )

# -----------------------------
# 3) Ensure project status exists (Completed / In Progress / Not Started)
# -----------------------------
if "project_status_gate_based" not in df.columns:
    gate_cnt = sum(F.when(F.col(c).isNotNull(), F.lit(1)).otherwise(F.lit(0)) for c in decision_cols)
    df = (df
          .withColumn("gate_dates_present_cnt", gate_cnt)
          .withColumn(
              "project_status_gate_based",
              F.when(F.col("gate_dates_present_cnt") == len(decision_cols), F.lit("Completed"))
               .when(F.col("gate_dates_present_cnt") == 0, F.lit("Not Started"))
               .otherwise(F.lit("In Progress"))
          )
    )

# -----------------------------
# 4) Timeliness per gate:
#    planned = Approval__date
#    actual  = Decision Date
#    delay_days = actual - planned  (positive => late)
# -----------------------------
gate_map = [
    ("A2", "Gate A2 Decision Date", "Gate A2 Approval Value__date"),
    ("B",  "Gate B Decision Date",  "Gate B Approval Value Sanction__date"),
    ("C",  "Gate C Decision Date",  "Gate C Approval Value FSA ACL__date"),
    ("D",  "Gate D Decision Date",  "Gate D Approval Value__date"),
    ("E",  "Gate E Decision Date",  "Gate E Approval Value__date"),
]

def gate_timeliness_status(actual_col, planned_col):
    actual = F.col(actual_col)
    planned = F.col(planned_col)

    # delay_days = actual - planned (positive means late)
    delay_days = F.datediff(actual, planned)

    status = (
        F.when(planned.isNull(), F.lit("NO_PLANNED_DATE"))
         .when(actual.isNotNull() & planned.isNotNull() & (delay_days > 0), F.lit("LATE"))
         .when(actual.isNotNull() & planned.isNotNull() & (delay_days == 0), F.lit("ON_TIME"))
         .when(actual.isNotNull() & planned.isNotNull() & (delay_days < 0), F.lit("EARLY"))
         # actual missing => either future/not due yet OR overdue (in progress / not started)
         .when(actual.isNull() & planned.isNotNull() & (planned > as_of_date), F.lit("FUTURE_NOT_DUE_YET"))
         .when(actual.isNull() & planned.isNotNull() & (planned <= as_of_date), F.lit("OVERDUE_NOT_STARTED"))
         .otherwise(F.lit("UNKNOWN"))
    )

    return delay_days, status

for g, actual_col, planned_col in gate_map:
    delay_col = f"gate_{g}_delay_days"
    status_col = f"gate_{g}_timeliness"

    delay_days, status = gate_timeliness_status(actual_col, planned_col)

    df = (df
          .withColumn(delay_col, delay_days)
          .withColumn(status_col, status)
    )

# -----------------------------
# 5) How to use it for your two cases
# -----------------------------
df_completed = df.filter(F.col("project_status_gate_based") == "Completed")
df_inprogress = df.filter(F.col("project_status_gate_based") == "In Progress")

# Example outputs you can display
display(
    df_completed.select(
        "Project ID",
        "project_status_gate_based",
        "Gate A2 Approval Value__date","Gate A2 Decision Date","gate_A2_delay_days","gate_A2_timeliness",
        "Gate B Approval Value Sanction__date","Gate B Decision Date","gate_B_delay_days","gate_B_timeliness",
        "Gate C Approval Value FSA ACL__date","Gate C Decision Date","gate_C_delay_days","gate_C_timeliness",
        "Gate D Approval Value__date","Gate D Decision Date","gate_D_delay_days","gate_D_timeliness",
        "Gate E Approval Value__date","Gate E Decision Date","gate_E_delay_days","gate_E_timeliness",
    ).limit(50)
)

display(
    df_inprogress.select(
        "Project ID",
        "project_status_gate_based",
        "Gate A2 Approval Value__date","Gate A2 Decision Date","gate_A2_delay_days","gate_A2_timeliness",
        "Gate B Approval Value Sanction__date","Gate B Decision Date","gate_B_delay_days","gate_B_timeliness",
        "Gate C Approval Value FSA ACL__date","Gate C Decision Date","gate_C_delay_days","gate_C_timeliness",
        "Gate D Approval Value__date","Gate D Decision Date","gate_D_delay_days","gate_D_timeliness",
        "Gate E Approval Value__date","Gate E Decision Date","gate_E_delay_days","gate_E_timeliness",
    ).limit(50)
)

# Optional: quick summary counts (late/on-time/overdue/future) per gate
for g, _, _ in gate_map:
    print(f"==== Gate {g} Timeliness (Completed) ====")
    display(df_completed.groupBy(f"gate_{g}_timeliness").count().orderBy(F.desc("count")))
    print(f"==== Gate {g} Timeliness (In Progress) ====")
    display(df_inprogress.groupBy(f"gate_{g}_timeliness").count().orderBy(F.desc("count")))

